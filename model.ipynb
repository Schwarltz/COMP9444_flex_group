{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride=1, expansion=6, downsample=None):\n",
    "    super(block, self).__init__()\n",
    "    middle_channels = in_channels*expansion\n",
    "\n",
    "    self.pass1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, middle_channels, 1, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(middle_channels),\n",
    "        nn.Mish(),\n",
    "        nn.Conv2d(middle_channels, middle_channels, 3, stride=stride, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(middle_channels),\n",
    "        nn.Mish(),\n",
    "        nn.Conv2d(middle_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.Mish(),\n",
    "    )\n",
    "\n",
    "    self.pass2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, middle_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(middle_channels),\n",
    "        nn.Mish(),\n",
    "        nn.Conv2d(middle_channels, middle_channels, kernel_size=3, stride=stride, padding=1,groups=in_channels, bias=False),\n",
    "        nn.BatchNorm2d(middle_channels),\n",
    "        nn.Mish(),\n",
    "        nn.Conv2d(middle_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.Mish(),\n",
    "    )\n",
    "\n",
    "    self.downsample = downsample\n",
    "  \n",
    "  def forward(self, x):\n",
    "    identity = x.clone()\n",
    "    x1 = self.pass1(x)\n",
    "    x2 = self.pass2(x)\n",
    "    x = x1 + x2\n",
    "    if self.downsample is not None:\n",
    "      identity = self.downsample(identity)\n",
    "    x += identity # always adds identity\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "  def __init__(self, in_channels=3, num_classes=10):\n",
    "    super(Network, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.relu6 = nn.Mish()\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    self.block1 = self._make_layer(block, 1, 32, 16, 1, 1)\n",
    "    self.block2 = self._make_layer(block, 6, 16, 24, 2, 2)\n",
    "    self.block3 = self._make_layer(block, 6, 24, 32, 3, 2)\n",
    "    self.block4 = self._make_layer(block, 6, 32, 64, 4, 2)\n",
    "    self.block5 = self._make_layer(block, 6, 64, 96, 3, 1)\n",
    "    self.block6 = self._make_layer(block, 6, 96, 160, 3, 2)\n",
    "    self.block7 = self._make_layer(block, 6, 160, 320, 1, 1)\n",
    "    \n",
    "    self.conv2 = nn.Conv2d(320,1280, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(1280)\n",
    "    self.avgPool = nn.AvgPool2d(7)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu6(x)\n",
    "    x = self.block1(x)\n",
    "    x = self.block2(x)\n",
    "    x = self.block3(x)\n",
    "    x = self.block4(x)\n",
    "    x = self.block5(x)\n",
    "    x = self.block6(x)\n",
    "    x = self.block7(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu6(x)\n",
    "    x = self.avgPool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x\n",
    "  \n",
    "  def _make_layer(self, block, expansion, in_channels, out_channels, repeats, stride):\n",
    "    layers = []\n",
    "    downsample = None\n",
    "\n",
    "    if stride != 1 or in_channels != out_channels: # identity convolution now occurs at least once in every function call\n",
    "      downsample = nn.Sequential(\n",
    "          nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride, bias=False),\n",
    "          nn.BatchNorm2d(out_channels),\n",
    "      )\n",
    "\n",
    "\n",
    "    layers.append(\n",
    "        block(in_channels, out_channels, stride, expansion, downsample)\n",
    "    )\n",
    "\n",
    "    for _ in range(repeats-1):\n",
    "      layers.append(\n",
    "          block(out_channels, out_channels, 1, expansion)\n",
    "      )\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "model = Network()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d53ec6266a26bc8bdfb2a6f99d7ada5f09e50f34a6a9bd31567b89d722776c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-CcsnEEgmNMA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "533c3e10-0938-4e54-82b6-a6301ddc9115"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='1557168128' class='' max='1557161267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1557168128/1557161267 00:35<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import packages\n",
        "\n",
        "import numpy as np    \n",
        "import matplotlib.pyplot as plt       \n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from fastai.vision.all import *\n",
        "set_seed(42, reproducible= True)\n",
        "source = untar_data(URLs.IMAGENETTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WfHz-aa2mPnj"
      },
      "outputs": [],
      "source": [
        "# Load and resize data\n",
        "\n",
        "# check learning rate decay, improve architecture (recent research papers)\n",
        "\n",
        "classes = (\"Tench\", \"English Springer\", \"Cassette Player\", \"Chain Saw\", \"Church\", \"French Horn\", \"Garbage Truck\", \"Gas Pump\", \"Golf Ball\", \"Parachute\")\n",
        "\n",
        "def load_data():\n",
        "  train = source/\"train\"\n",
        "  val = source/\"val\"\n",
        "\n",
        "  train_dataset = ImageFolder(\n",
        "    train,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(128),\n",
        "        transforms.RandomCrop(128), \n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4663, 0.4590, 0.4300), (0.2764, 0.2721, 0.2951)),\n",
        "        transforms.RandomErasing()\n",
        "    ]))\n",
        "\n",
        "  val_dataset = ImageFolder(\n",
        "    val,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(128),\n",
        "        transforms.RandomCrop(128), \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4663, 0.4590, 0.4300), (0.2764, 0.2721, 0.2951))\n",
        "    ]))\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "  val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "  \n",
        "  return train_dataloader, val_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKQhznn9mVL",
        "outputId": "28f32855-2a07-4b81-b31e-7252d9d0879b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0002,  0.0017,  0.0015]) tensor([0.9574, 0.9580, 0.9581])\n"
          ]
        }
      ],
      "source": [
        "def get_mean_std(dl):\n",
        "    sum_, squared_sum, batches = 0,0,0\n",
        "    for data, _ in dl:\n",
        "        sum_ += torch.mean(data,dim=([0,2,3]))\n",
        "        squared_sum += torch.mean(data**2, dim=([0,2,3]))\n",
        "        batches += 1\n",
        "    mean = sum_/batches\n",
        "    std = (squared_sum/batches-mean**2)**0.5\n",
        "    return mean,std\n",
        "\n",
        "train_dl, test_dl = load_data()\n",
        "mean, std = get_mean_std(train_dl)\n",
        "print(mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-OweNtKxnLK9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Taken from https://github.com/digantamisra98/Mish/tree/master/Mish/Torch\n",
        "Applies the mish function element-wise:\n",
        "mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "\"\"\"\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    \"\"\"\n",
        "    Applies the mish function element-wise:\n",
        "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
        "    Shape:\n",
        "        - Input: (N, *) where * means, any number of additional\n",
        "          dimensions\n",
        "        - Output: (N, *), same shape as the input\n",
        "    Examples:\n",
        "        >>> m = Mish()\n",
        "        >>> input = torch.randn(2)\n",
        "        >>> output = m(input)\n",
        "    Reference: https://pytorch.org/docs/stable/generated/torch.nn.Mish.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Init method.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Forward pass of the function.\n",
        "        \"\"\"\n",
        "        if torch.__version__ >= \"1.9\":\n",
        "            return F.mish(input)\n",
        "        else:\n",
        "            return input * torch.tanh(F.softplus(input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqE3lfy1nNAY"
      },
      "outputs": [],
      "source": [
        "# Define a convolution neural network (simple)\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network, self).__init__()\n",
        "        \n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(12)\n",
        "    self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(12)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "    self.bn4 = nn.BatchNorm2d(24)\n",
        "    self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "    self.bn5 = nn.BatchNorm2d(24)\n",
        "    self.conv6 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=5, stride=1, padding=1)\n",
        "    self.bn6 = nn.BatchNorm2d(32)\n",
        "    self.conv7 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=1)\n",
        "    self.fc1 = nn.Linear(64*25*25, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "  \n",
        "  def forward(self, input):\n",
        "    m = Mish()\n",
        "    output = m(self.bn1(self.conv1(input.cuda())))      \n",
        "    output = m(self.bn2(self.conv2(output)))     \n",
        "    output = self.pool(output)                        \n",
        "    output = m(self.bn4(self.conv4(output)))     \n",
        "    output = m(self.bn5(self.conv5(output)))     \n",
        "    output = self.pool(output)\n",
        "    output = m(self.bn6(self.conv6(output)))\n",
        "    output = m(self.conv7(output))\n",
        "    output = output.view(-1, 64*25*25)\n",
        "    output = m(self.fc1(output))\n",
        "    output = self.fc2(output)\n",
        "    output = F.log_softmax(output, dim=1)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Instantiate a neural network model \n",
        "model2 = Network()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GoogLeNet From pytorch official website \"\"\"\n",
        "from collections import namedtuple\n",
        "from typing import Optional, Tuple, List, Callable, Any\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 1000,\n",
        "        transform_input: bool = False,\n",
        "        init_weights: Optional[bool] = None,\n",
        "        blocks: Optional[List[Callable[..., nn.Module]]] = None,\n",
        "        dropout: float = 0.2\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if blocks is None:\n",
        "            blocks = [BasicConv2d, Inception]\n",
        "        if init_weights is None:\n",
        "            init_weights = True\n",
        "        assert len(blocks) == 2\n",
        "        conv_block = blocks[0]\n",
        "        inception_block = blocks[1]\n",
        "\n",
        "        self.transform_input = transform_input\n",
        "\n",
        "        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "        self.conv2 = conv_block(64, 64, kernel_size=1)\n",
        "        self.conv3 = conv_block(64, 192, kernel_size=3, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception3a = inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = inception_block(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "        if init_weights:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=0.01, a=-2, b=2)\n",
        "                elif isinstance(m, nn.BatchNorm2d):\n",
        "                    nn.init.constant_(m.weight, 1)\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _transform_input(self, x: Tensor) -> Tensor:\n",
        "        if self.transform_input:\n",
        "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # N x 3 x 224 x 224\n",
        "        x = self.conv1(x)\n",
        "        # N x 64 x 112 x 112\n",
        "        x = self.maxpool1(x)\n",
        "        # N x 64 x 56 x 56\n",
        "        x = self.conv2(x)\n",
        "        # N x 64 x 56 x 56\n",
        "        x = self.conv3(x)\n",
        "        # N x 192 x 56 x 56\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # N x 192 x 28 x 28\n",
        "        x = self.inception3a(x)\n",
        "        # N x 256 x 28 x 28\n",
        "        x = self.inception3b(x)\n",
        "        # N x 480 x 28 x 28\n",
        "        x = self.maxpool3(x)\n",
        "        # N x 480 x 14 x 14\n",
        "        x = self.inception4a(x)\n",
        "        # N x 512 x 14 x 14\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        x = self.inception4c(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        x = self.inception4d(x)\n",
        "        # N x 528 x 14 x 14\n",
        "        x = self.inception4e(x)\n",
        "        # N x 832 x 14 x 14\n",
        "        x = self.maxpool4(x)\n",
        "        # N x 832 x 7 x 7\n",
        "        x = self.inception5a(x)\n",
        "        # N x 832 x 7 x 7\n",
        "        x = self.inception5b(x)\n",
        "        # N x 1024 x 7 x 7\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        # N x 1024 x 1 x 1\n",
        "        x = torch.flatten(x, 1)\n",
        "        # N x 1024\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        # N x 1000 (num_classes)\n",
        "        return x\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        ch1x1: int,\n",
        "        ch3x3red: int,\n",
        "        ch3x3: int,\n",
        "        ch5x5red: int,\n",
        "        ch5x5: int,\n",
        "        pool_proj: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if conv_block is None:\n",
        "            conv_block = BasicConv2d\n",
        "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, ch3x3red, kernel_size=1), conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
        "            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n",
        "            # Please see https://github.com/pytorch/vision/issues/906 for details.\n",
        "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
        "            conv_block(in_channels, pool_proj, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "\n",
        "        outputs = [branch1, branch2, branch3, branch4]\n",
        "        return outputs\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        outputs = self._forward(x)\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        m = Mish()\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return m(x)\n",
        "\n",
        "model = GoogLeNet()"
      ],
      "metadata": {
        "id": "DkCIo2M-cEL4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "    ResNet50D based on 'Bag of Tricks for Image Classification with Convolutional Neural Networks' \n",
        "    (https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf) \n",
        "    replacing relu with mish\n",
        "    modified from https://github.com/JayPatwardhan/ResNet-PyTorch/blob/master/ResNet/ResNet.py\n",
        "\"\"\"\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        \n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        m = Mish()\n",
        "        x = m(self.batch_norm1(self.conv1(x)))\n",
        "        \n",
        "        x = m(self.batch_norm2(self.conv2(x)))\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        \n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        \n",
        "        x += identity\n",
        "        x = m(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class ResNet50D(nn.Module):\n",
        "    def __init__(self, block):\n",
        "        super(ResNet50D, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(block, 3, planes=64)\n",
        "        self.layer2 = self._make_layer(block, 4, planes=128, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 6, planes=256, stride=2)\n",
        "        self.layer4 = self._make_layer(block, 3, planes=512, stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*block.expansion, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        m = Mish()\n",
        "        x = m(self.batch_norm1(self.conv1(x)))\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "        \n",
        "        if stride != 1:\n",
        "          ii_downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=1),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "        elif self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "            \n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "        \n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "            \n",
        "        return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "-DcSNvGT2yF3"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cu-vdVF7nQ05"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "\n",
        "# Function to save the model\n",
        "def saveModel(cnn, p):\n",
        "    path = \"./\"+p\n",
        "    torch.save(cnn.state_dict(), path)\n",
        "\n",
        "# Function to test the model with the test dataset and print the accuracy for the test images\n",
        "def testAccuracy(cnn, device):\n",
        "    \n",
        "    cnn.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = cnn(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "def trainAccuracy(cnn, device):\n",
        "\n",
        "    cnn.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in train_loader:\n",
        "            images, labels = data\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = cnn(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "\n",
        "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
        "def train(cnn, num_epochs, path):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    cnn.to(device)\n",
        " \n",
        "    # Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(cnn.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "    all_accuracy = []\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            # get the inputs\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = cnn(images)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 1000 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i % 1000 == 999:    \n",
        "                # print every 50 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Compute and print the average accuracy for this epoch when tested over all test images\n",
        "        accuracy = testAccuracy(cnn, device)\n",
        "        train_accuracy = trainAccuracy(cnn, device)\n",
        "        all_accuracy.append(accuracy)\n",
        "        print('For epoch', epoch+1,'the train accuracy is %d %%' % (train_accuracy), 'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "        \n",
        "        # we want to save the model if the accuracy is the best\n",
        "        if accuracy > best_accuracy:\n",
        "            saveModel(cnn, path)\n",
        "            best_accuracy = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZciMyoBCnSS1"
      },
      "outputs": [],
      "source": [
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    if torch.cuda.is_available():\n",
        "      npimg = img.cpu().numpy()\n",
        "    else:\n",
        "      npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to test the model with a batch of images and show the labels predictions\n",
        "def testBatch(batch_size):\n",
        "    # get batch of images from the test DataLoader  \n",
        "    images, labels = next(iter(test_loader))\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))\n",
        "   \n",
        "    # Show the real labels on the screen \n",
        "    print('Real labels: ', ', '.join('%5s' % classes[labels[j]] \n",
        "                               for j in range(batch_size)))\n",
        "  \n",
        "    # Let's see what if the model identifiers the  labels of those example\n",
        "    outputs = model(images)\n",
        "    \n",
        "    # We got the probability for every 10 labels. The highest (max) probability should be correct label\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    # Let's show the predicted labels on the screen to compare with the real ones\n",
        "    print('Predicted: ', ', '.join('%5s' % classes[predicted[j]] \n",
        "                              for j in range(batch_size)))\n",
        "\n",
        "def testClassess(batch_size, number_of_labels):\n",
        "    class_correct = list(0. for i in range(number_of_labels))\n",
        "    class_total = list(0. for i in range(number_of_labels))\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            if torch.cuda.is_available():\n",
        "              images = images.cuda()\n",
        "              labels = labels.cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(batch_size):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    for i in range(number_of_labels):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_lUZaXmZnVDn"
      },
      "outputs": [],
      "source": [
        "# Let's build our model\n",
        "train_loader, test_loader = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogLeNet()\n",
        "\n",
        "train(model, 80, 'classifier_GoogLeNet.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "bExag8zdkImz",
        "outputId": "83f380bc-39a8-4ddc-acef-1ac37e1d6c8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model will be running on cuda:0 device\n",
            "For epoch 1 the train accuracy is 41 % the test accuracy over the whole test set is 40 %\n",
            "For epoch 2 the train accuracy is 36 % the test accuracy over the whole test set is 35 %\n",
            "For epoch 3 the train accuracy is 41 % the test accuracy over the whole test set is 41 %\n",
            "For epoch 4 the train accuracy is 43 % the test accuracy over the whole test set is 42 %\n",
            "For epoch 5 the train accuracy is 52 % the test accuracy over the whole test set is 52 %\n",
            "For epoch 6 the train accuracy is 52 % the test accuracy over the whole test set is 50 %\n",
            "For epoch 7 the train accuracy is 57 % the test accuracy over the whole test set is 58 %\n",
            "For epoch 8 the train accuracy is 60 % the test accuracy over the whole test set is 60 %\n",
            "For epoch 9 the train accuracy is 65 % the test accuracy over the whole test set is 65 %\n",
            "For epoch 10 the train accuracy is 61 % the test accuracy over the whole test set is 61 %\n",
            "For epoch 11 the train accuracy is 64 % the test accuracy over the whole test set is 64 %\n",
            "For epoch 12 the train accuracy is 67 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 13 the train accuracy is 67 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 14 the train accuracy is 69 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 15 the train accuracy is 73 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 16 the train accuracy is 68 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 17 the train accuracy is 73 % the test accuracy over the whole test set is 71 %\n",
            "For epoch 18 the train accuracy is 73 % the test accuracy over the whole test set is 72 %\n",
            "For epoch 19 the train accuracy is 74 % the test accuracy over the whole test set is 71 %\n",
            "For epoch 20 the train accuracy is 76 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 21 the train accuracy is 77 % the test accuracy over the whole test set is 75 %\n",
            "For epoch 22 the train accuracy is 76 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 23 the train accuracy is 77 % the test accuracy over the whole test set is 75 %\n",
            "For epoch 24 the train accuracy is 79 % the test accuracy over the whole test set is 76 %\n",
            "For epoch 25 the train accuracy is 78 % the test accuracy over the whole test set is 75 %\n",
            "For epoch 26 the train accuracy is 80 % the test accuracy over the whole test set is 76 %\n",
            "For epoch 27 the train accuracy is 77 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 28 the train accuracy is 81 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 29 the train accuracy is 80 % the test accuracy over the whole test set is 76 %\n",
            "For epoch 30 the train accuracy is 77 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 31 the train accuracy is 82 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 32 the train accuracy is 83 % the test accuracy over the whole test set is 78 %\n",
            "For epoch 33 the train accuracy is 81 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 34 the train accuracy is 80 % the test accuracy over the whole test set is 76 %\n",
            "For epoch 35 the train accuracy is 83 % the test accuracy over the whole test set is 78 %\n",
            "For epoch 36 the train accuracy is 82 % the test accuracy over the whole test set is 77 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4f50f21efaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier_GoogLeNet.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-49bcc5053e38>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cnn, num_epochs, path)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Compute and print the average accuracy for this epoch when tested over all test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mall_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'the train accuracy is %d %%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the test accuracy over the whole test set is %d %%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-49bcc5053e38>\u001b[0m in \u001b[0;36mtrainAccuracy\u001b[0;34m(cnn, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;31m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/load.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self, samps)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mchunked\u001b[0;34m(it, chunk_sz, drop_last, n_chunks)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mchunk_sz\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mchunk_sz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/load.py\u001b[0m in \u001b[0;36mdo_item\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprebatched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSkipItemException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchunkify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebatched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data/load.py\u001b[0m in \u001b[0;36mcreate_item\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mretain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mretain_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index an iterable dataset numerically - must use `None`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[1;32m    229\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \"\"\"\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50D(Bottleneck)\n",
        "\n",
        "train(model, 80, 'classifier_ResNet50D.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isHwVWJ6Pa5u",
        "outputId": "47ed4baf-e250-4d8d-80a0-e2c8e1a603e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model will be running on cuda:0 device\n",
            "For epoch 1 the train accuracy is 40 % the test accuracy over the whole test set is 40 %\n",
            "For epoch 2 the train accuracy is 42 % the test accuracy over the whole test set is 41 %\n",
            "For epoch 3 the train accuracy is 43 % the test accuracy over the whole test set is 42 %\n",
            "For epoch 4 the train accuracy is 51 % the test accuracy over the whole test set is 52 %\n",
            "For epoch 5 the train accuracy is 59 % the test accuracy over the whole test set is 60 %\n",
            "For epoch 6 the train accuracy is 61 % the test accuracy over the whole test set is 62 %\n",
            "For epoch 7 the train accuracy is 65 % the test accuracy over the whole test set is 65 %\n",
            "For epoch 8 the train accuracy is 68 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 9 the train accuracy is 67 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 10 the train accuracy is 66 % the test accuracy over the whole test set is 65 %\n",
            "For epoch 11 the train accuracy is 71 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 12 the train accuracy is 70 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 13 the train accuracy is 69 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 14 the train accuracy is 76 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 15 the train accuracy is 75 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 16 the train accuracy is 75 % the test accuracy over the whole test set is 72 %\n",
            "For epoch 17 the train accuracy is 76 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 18 the train accuracy is 79 % the test accuracy over the whole test set is 76 %\n",
            "For epoch 19 the train accuracy is 77 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 20 the train accuracy is 78 % the test accuracy over the whole test set is 75 %\n",
            "For epoch 21 the train accuracy is 80 % the test accuracy over the whole test set is 76 %\n",
            "For epoch 22 the train accuracy is 79 % the test accuracy over the whole test set is 76 %\n",
            "For epoch 23 the train accuracy is 78 % the test accuracy over the whole test set is 74 %\n",
            "For epoch 24 the train accuracy is 82 % the test accuracy over the whole test set is 78 %\n",
            "For epoch 25 the train accuracy is 80 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 26 the train accuracy is 82 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 27 the train accuracy is 83 % the test accuracy over the whole test set is 78 %\n",
            "For epoch 28 the train accuracy is 83 % the test accuracy over the whole test set is 78 %\n",
            "For epoch 29 the train accuracy is 84 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 30 the train accuracy is 85 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 31 the train accuracy is 83 % the test accuracy over the whole test set is 78 %\n",
            "For epoch 32 the train accuracy is 82 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 33 the train accuracy is 86 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 34 the train accuracy is 84 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 35 the train accuracy is 85 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 36 the train accuracy is 87 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 37 the train accuracy is 86 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 38 the train accuracy is 85 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 39 the train accuracy is 88 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 40 the train accuracy is 86 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 41 the train accuracy is 85 % the test accuracy over the whole test set is 78 %\n",
            "For epoch 42 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 43 the train accuracy is 90 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 44 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 45 the train accuracy is 88 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 46 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 47 the train accuracy is 89 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 48 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 49 the train accuracy is 88 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 50 the train accuracy is 86 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 51 the train accuracy is 90 % the test accuracy over the whole test set is 82 %\n",
            "For epoch 52 the train accuracy is 91 % the test accuracy over the whole test set is 81 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(20) # epochs 40 - 60 for GoogLeNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZNojHyu99OS",
        "outputId": "61308a36-8793-411f-8684-9ec0bde797ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model will be running on cuda:0 device\n",
            "For epoch 1 the train accuracy is 82 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 2 the train accuracy is 85 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 3 the train accuracy is 86 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 4 the train accuracy is 86 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 5 the train accuracy is 86 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 6 the train accuracy is 85 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 7 the train accuracy is 85 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 8 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 9 the train accuracy is 88 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 10 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 11 the train accuracy is 88 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 12 the train accuracy is 89 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 13 the train accuracy is 89 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 14 the train accuracy is 87 % the test accuracy over the whole test set is 79 %\n",
            "For epoch 15 the train accuracy is 84 % the test accuracy over the whole test set is 77 %\n",
            "For epoch 16 the train accuracy is 88 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 17 the train accuracy is 89 % the test accuracy over the whole test set is 82 %\n",
            "For epoch 18 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "For epoch 19 the train accuracy is 89 % the test accuracy over the whole test set is 81 %\n",
            "For epoch 20 the train accuracy is 87 % the test accuracy over the whole test set is 80 %\n",
            "The average accuracy over 20  runs is 80.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Owsc5-a-CU76"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "main.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
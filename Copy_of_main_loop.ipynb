{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_UtqxCeu2xu"
      },
      "outputs": [],
      "source": [
        "import numpy as np    \n",
        "import matplotlib.pyplot as plt       \n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Google Colab\n",
        "from fastai.vision.all import *\n",
        "set_seed(42, reproducible= True)\n",
        "source = untar_data(URLs.IMAGENETTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-B1TZyNu2xz"
      },
      "outputs": [],
      "source": [
        "classes = (\"Tench\", \"English Springer\", \"Cassette Player\", \"Chain Saw\", \"Church\", \"French Horn\", \"Garbage Truck\", \"Gas Pump\", \"Golf Ball\", \"Parachute\")\n",
        "batch_size = 64\n",
        "width = 224\n",
        "mean = [0.4655, 0.4546, 0.4251]\n",
        "std = [0.2775, 0.2725, 0.2938]\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  train = source/\"train\"\n",
        "  val = source/\"val\"\n",
        "\n",
        "  train_dataset = ImageFolder(\n",
        "    train,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(280),\n",
        "        transforms.RandomCrop(width), \n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "        transforms.RandomErasing()\n",
        "    ]))\n",
        "\n",
        "  val_dataset = ImageFolder(\n",
        "    val,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(280),\n",
        "        transforms.RandomCrop(width), \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]))\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "  val_dataloader = DataLoader(val_dataset, batch_size)\n",
        "  \n",
        "  return train_dataloader, val_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Y9DMp-u2x0"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxy6zB8Cu2x1"
      },
      "outputs": [],
      "source": [
        "# 80 epochs: 61% training 59% testing\n",
        "\n",
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride, expansion, downsample=None):\n",
        "    super(block, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(in_channels, in_channels*expansion, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(in_channels*expansion)\n",
        "    self.conv2 = nn.Conv2d(in_channels*expansion, in_channels*expansion, kernel_size=3, stride=stride, padding=1,groups=in_channels, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(in_channels*expansion)\n",
        "    self.conv3 = nn.Conv2d(in_channels*expansion, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    self.dropout = nn.Dropout2d(0.1)\n",
        "    self.relu6 = nn.ReLU6()\n",
        "    self.downsample = downsample\n",
        "  \n",
        "  def forward(self, x):\n",
        "    identity = x.clone()\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu6(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu6(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.relu6(x)\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(identity)\n",
        "      x += identity\n",
        "    return x\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self, in_channels=3, num_classes=10):\n",
        "    super(Network, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=7, stride=2, padding=3, bias=False) # initial convolution 112*112*64\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    # self.block1 = block(32, 16, 1, expansion=1)\n",
        "    self.block1 = self._make_layer(block, 1, 32, 16, 1, 1)\n",
        "    self.block2 = self._make_layer(block, 6, 16, 24, 2, 2)\n",
        "    self.block3 = self._make_layer(block, 6, 24, 32, 3, 2)\n",
        "    self.block4 = self._make_layer(block, 6, 32, 64, 4, 2)\n",
        "    self.block5 = self._make_layer(block, 6, 64, 96, 3, 1)\n",
        "    self.block6 = self._make_layer(block, 6, 96, 160, 3, 2)\n",
        "    self.block7 = self._make_layer(block, 6, 160, 320, 1, 1)\n",
        "    self.conv2 = nn.Conv2d(320,1280, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(1280)\n",
        "    self.avgPool = nn.AvgPool2d(7)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Linear(1280, num_classes)\n",
        "\n",
        "    self.dropout = nn.Dropout2d(0.1)\n",
        "    self.relu6 = nn.ReLU6()\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu6(x)\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    x = self.block5(x)\n",
        "    x = self.block6(x)\n",
        "    x = self.block7(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu6(x)\n",
        "    x = self.avgPool(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  def _make_layer(self, block, expansion, in_channels, out_channels, repeats, stride):\n",
        "    layers = []\n",
        "    downsample = None\n",
        "\n",
        "    if stride != 1:\n",
        "      downsample = nn.Sequential(\n",
        "          nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(out_channels),\n",
        "      )\n",
        "\n",
        "\n",
        "    layers.append(\n",
        "        block(in_channels, out_channels, stride, expansion, downsample)\n",
        "    )\n",
        "\n",
        "    for _ in range(repeats-1):\n",
        "      layers.append(\n",
        "          block(out_channels, out_channels, 1, expansion)\n",
        "      )\n",
        "    \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "model = Network()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title ResNet: Not own code (20 epochs, % training, 17% testing)\n",
        "\n",
        "# class block(nn.Module):\n",
        "#     def __init__(\n",
        "#         self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
        "#     ):\n",
        "#         super(block, self).__init__()\n",
        "#         self.expansion = 4\n",
        "#         self.conv1 = nn.Conv2d(\n",
        "#               in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
        "#           ) # [_, int_channels, x,y]\n",
        "#         self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "#         self.conv2 = nn.Conv2d(\n",
        "#             intermediate_channels,\n",
        "#             intermediate_channels,\n",
        "#             kernel_size=3,\n",
        "#             stride=stride,\n",
        "#             padding=1,\n",
        "#             bias=False\n",
        "#         ) # [_, int_channels, x,y]\n",
        "#         self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "#         self.conv3 = nn.Conv2d(\n",
        "#             intermediate_channels,\n",
        "#             intermediate_channels * self.expansion,\n",
        "#             kernel_size=1,\n",
        "#             stride=1,\n",
        "#             padding=0,\n",
        "#             bias=False\n",
        "#         ) # [_, int_channels*4, x, y]\n",
        "#         self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.identity_downsample = identity_downsample\n",
        "#         self.stride = stride\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         identity = x.clone()\n",
        "\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.bn2(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.conv3(x)\n",
        "#         x = self.bn3(x)\n",
        "\n",
        "#         if self.identity_downsample is not None:\n",
        "#             identity = self.identity_downsample(identity)\n",
        "\n",
        "#         x += identity\n",
        "#         x = self.relu(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# class ResNet(nn.Module):\n",
        "#     def __init__(self, block, layers, image_channels, num_classes):\n",
        "#         super(ResNet, self).__init__()\n",
        "#         self.in_channels = 64\n",
        "#         self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(64)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "#         # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "#         self.layer1 = self._make_layer(\n",
        "#             block, layers[0], intermediate_channels=64, stride=1\n",
        "#         )\n",
        "#         self.layer2 = self._make_layer(\n",
        "#             block, layers[1], intermediate_channels=128, stride=2\n",
        "#         )\n",
        "#         self.layer3 = self._make_layer(\n",
        "#             block, layers[2], intermediate_channels=256, stride=2\n",
        "#         )\n",
        "#         self.layer4 = self._make_layer(\n",
        "#             block, layers[3], intermediate_channels=512, stride=2\n",
        "#         )\n",
        "\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.maxpool(x)\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.layer4(x)\n",
        "\n",
        "#         x = self.avgpool(x)\n",
        "#         x = x.reshape(x.shape[0], -1)\n",
        "#         x = self.fc(x)\n",
        "\n",
        "#         return x\n",
        "\n",
        "#     def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "#         identity_downsample = None\n",
        "#         layers = []\n",
        "\n",
        "#         # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "#         # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "#         # to the layer that's ahead\n",
        "#         if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "#             identity_downsample = nn.Sequential(\n",
        "#                 nn.Conv2d(\n",
        "#                     self.in_channels,\n",
        "#                     intermediate_channels * 4,\n",
        "#                     kernel_size=1,\n",
        "#                     stride=stride,\n",
        "#                     bias=False\n",
        "#                 ),\n",
        "#                 nn.BatchNorm2d(intermediate_channels * 4),\n",
        "#             )\n",
        "\n",
        "#         layers.append(\n",
        "#             block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "#         )\n",
        "\n",
        "#         # The expansion size is always 4 for ResNet 50,101,152\n",
        "#         self.in_channels = intermediate_channels * 4\n",
        "\n",
        "#         # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "#         # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "#         # and also same amount of channels.\n",
        "#         for i in range(num_residual_blocks - 1):\n",
        "#             layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "#         return nn.Sequential(*layers)\n",
        "\n",
        "# network = ResNet(block, [3,4,6,3], image_channels=3, num_classes=10)"
      ],
      "metadata": {
        "id": "c3arPd1qGHwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/MobileNetv2_60acc.pth'\n",
        "model = Network()\n",
        "model.load_state_dict(torch.load(path))\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kskIYJU0OTKh",
        "outputId": "91b57bd9-9a50-4d41-8104-6b01cb70f316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (block1): Sequential(\n",
            "    (0): block(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "  )\n",
            "  (block2): Sequential(\n",
            "    (0): block(\n",
            "      (conv1): Conv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): block(\n",
            "      (conv1): Conv2d(24, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
            "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "  )\n",
            "  (block3): Sequential(\n",
            "    (0): block(\n",
            "      (conv1): Conv2d(24, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
            "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(24, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): block(\n",
            "      (conv1): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "    (2): block(\n",
            "      (conv1): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "  )\n",
            "  (block4): Sequential(\n",
            "    (0): block(\n",
            "      (conv1): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): block(\n",
            "      (conv1): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "    (2): block(\n",
            "      (conv1): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "    (3): block(\n",
            "      (conv1): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "  )\n",
            "  (block5): Sequential(\n",
            "    (0): block(\n",
            "      (conv1): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "    (1): block(\n",
            "      (conv1): Conv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "    (2): block(\n",
            "      (conv1): Conv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "  )\n",
            "  (block6): Sequential(\n",
            "    (0): block(\n",
            "      (conv1): Conv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(96, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): block(\n",
            "      (conv1): Conv2d(160, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
            "      (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "    (2): block(\n",
            "      (conv1): Conv2d(160, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
            "      (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "  )\n",
            "  (block7): Sequential(\n",
            "    (0): block(\n",
            "      (conv1): Conv2d(160, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
            "      (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (relu6): ReLU6()\n",
            "    )\n",
            "  )\n",
            "  (conv2): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (avgPool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc): Linear(in_features=1280, out_features=10, bias=True)\n",
            "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "  (relu6): ReLU6()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSNynAhFu2x2"
      },
      "source": [
        "Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI8I5GzNu2x3"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam, SGD, lr_scheduler\n",
        "\n",
        "# Function to save the model\n",
        "def saveModel():\n",
        "    path = \"./classifier_full.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# Function to test the model with the test dataset and print the accuracy for the test images\n",
        "def testAccuracy(device):\n",
        "    \n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = model(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "def trainAccuracy(device):\n",
        "\n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in train_loader:\n",
        "            images, labels = data\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = model(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "def train(num_epochs):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    # Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.00004)\n",
        "    # optimizer = Adam(model.parameters(), lr=0.001, weight_decay = 0.00001)\n",
        "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "    all_accuracy = []\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            # get the inputs\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(images)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 50 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i % 10 == 10:    \n",
        "                # print every 50 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.8f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Compute and print the average accuracy for this epoch when tested over all test images\n",
        "        accuracy = testAccuracy(device)\n",
        "        train_accuracy = trainAccuracy(device)\n",
        "        all_accuracy.append(accuracy)\n",
        "        print('For epoch', epoch+1,'the train accuracy is %d %%' % (train_accuracy), 'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "        \n",
        "        # we want to save the model if the accuracy is the best\n",
        "        if accuracy > best_accuracy:\n",
        "            saveModel()\n",
        "            best_accuracy = accuracy\n",
        "\n",
        "        scheduler.step()\n",
        "    print('The average accuracy over %d' % num_epochs, ' runs is %.2f' % (sum(all_accuracy)/num_epochs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZXKn5Vau2x4"
      },
      "source": [
        "Showing Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhu6-ZnBu2x5"
      },
      "outputs": [],
      "source": [
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    if torch.cuda.is_available():\n",
        "      npimg = img.cpu().numpy()\n",
        "    else:\n",
        "      npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpCcP0yCu2x5"
      },
      "outputs": [],
      "source": [
        "def checkTransformedImages():\n",
        "    # get batch of images from the test DataLoader\n",
        "    images, labels = next(iter(test_loader))\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opk11Quiu2x6"
      },
      "source": [
        "Run Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzGEHXM6u2x6",
        "outputId": "19fca678-2345-4130-d879-1ec7897a6db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model will be running on cuda:0 device\n",
            "For epoch 1 the train accuracy is 44 % the test accuracy over the whole test set is 44 %\n",
            "For epoch 2 the train accuracy is 52 % the test accuracy over the whole test set is 50 %\n",
            "For epoch 3 the train accuracy is 55 % the test accuracy over the whole test set is 54 %\n",
            "For epoch 4 the train accuracy is 58 % the test accuracy over the whole test set is 57 %\n",
            "For epoch 5 the train accuracy is 60 % the test accuracy over the whole test set is 60 %\n",
            "For epoch 6 the train accuracy is 60 % the test accuracy over the whole test set is 58 %\n",
            "For epoch 7 the train accuracy is 60 % the test accuracy over the whole test set is 60 %\n",
            "For epoch 8 the train accuracy is 62 % the test accuracy over the whole test set is 59 %\n",
            "For epoch 9 the train accuracy is 63 % the test accuracy over the whole test set is 62 %\n",
            "For epoch 10 the train accuracy is 63 % the test accuracy over the whole test set is 61 %\n",
            "For epoch 11 the train accuracy is 63 % the test accuracy over the whole test set is 62 %\n",
            "For epoch 12 the train accuracy is 63 % the test accuracy over the whole test set is 62 %\n",
            "For epoch 13 the train accuracy is 65 % the test accuracy over the whole test set is 62 %\n",
            "For epoch 14 the train accuracy is 64 % the test accuracy over the whole test set is 62 %\n",
            "For epoch 15 the train accuracy is 65 % the test accuracy over the whole test set is 63 %\n",
            "For epoch 16 the train accuracy is 66 % the test accuracy over the whole test set is 62 %\n",
            "For epoch 17 the train accuracy is 66 % the test accuracy over the whole test set is 64 %\n",
            "For epoch 18 the train accuracy is 66 % the test accuracy over the whole test set is 63 %\n",
            "For epoch 19 the train accuracy is 67 % the test accuracy over the whole test set is 65 %\n",
            "For epoch 20 the train accuracy is 67 % the test accuracy over the whole test set is 64 %\n",
            "For epoch 21 the train accuracy is 67 % the test accuracy over the whole test set is 64 %\n",
            "For epoch 22 the train accuracy is 68 % the test accuracy over the whole test set is 64 %\n",
            "For epoch 23 the train accuracy is 68 % the test accuracy over the whole test set is 65 %\n",
            "For epoch 24 the train accuracy is 66 % the test accuracy over the whole test set is 64 %\n",
            "For epoch 25 the train accuracy is 67 % the test accuracy over the whole test set is 64 %\n",
            "For epoch 26 the train accuracy is 69 % the test accuracy over the whole test set is 65 %\n",
            "For epoch 27 the train accuracy is 70 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 28 the train accuracy is 69 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 29 the train accuracy is 70 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 30 the train accuracy is 70 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 31 the train accuracy is 69 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 32 the train accuracy is 71 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 33 the train accuracy is 72 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 34 the train accuracy is 70 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 35 the train accuracy is 71 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 36 the train accuracy is 71 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 37 the train accuracy is 69 % the test accuracy over the whole test set is 65 %\n",
            "For epoch 38 the train accuracy is 72 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 39 the train accuracy is 72 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 40 the train accuracy is 72 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 41 the train accuracy is 72 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 42 the train accuracy is 72 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 43 the train accuracy is 73 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 44 the train accuracy is 71 % the test accuracy over the whole test set is 66 %\n",
            "For epoch 45 the train accuracy is 73 % the test accuracy over the whole test set is 67 %\n",
            "For epoch 46 the train accuracy is 74 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 47 the train accuracy is 74 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 48 the train accuracy is 75 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 49 the train accuracy is 74 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 50 the train accuracy is 75 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 51 the train accuracy is 74 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 52 the train accuracy is 75 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 53 the train accuracy is 75 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 54 the train accuracy is 74 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 55 the train accuracy is 74 % the test accuracy over the whole test set is 68 %\n",
            "For epoch 56 the train accuracy is 75 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 57 the train accuracy is 75 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 58 the train accuracy is 75 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 59 the train accuracy is 76 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 60 the train accuracy is 76 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 61 the train accuracy is 76 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 62 the train accuracy is 77 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 63 the train accuracy is 77 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 64 the train accuracy is 76 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 65 the train accuracy is 77 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 66 the train accuracy is 76 % the test accuracy over the whole test set is 69 %\n",
            "For epoch 67 the train accuracy is 77 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 68 the train accuracy is 77 % the test accuracy over the whole test set is 71 %\n",
            "For epoch 69 the train accuracy is 78 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 70 the train accuracy is 78 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 71 the train accuracy is 78 % the test accuracy over the whole test set is 71 %\n",
            "For epoch 72 the train accuracy is 77 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 73 the train accuracy is 78 % the test accuracy over the whole test set is 70 %\n",
            "For epoch 74 the train accuracy is 78 % the test accuracy over the whole test set is 70 %\n"
          ]
        }
      ],
      "source": [
        "train_loader, test_loader = load_data()\n",
        "\n",
        "num_epochs = 80\n",
        "train(num_epochs)\n",
        "\n",
        "checkTransformedImages()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "cQjZsAbe5CcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5b07cb-afef-4eb5-8b85-638fea88aa1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAvu0UtnNxZ0",
        "outputId": "45c6a568-729d-4ad9-e596-00ba2b9f299d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Copy of main_loop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h_UtqxCeu2xu"
      },
      "outputs": [],
      "source": [
        "import numpy as np    \n",
        "import matplotlib.pyplot as plt       \n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Google Colab\n",
        "from fastai.vision.all import *\n",
        "set_seed(42, reproducible= True)\n",
        "source = untar_data(URLs.IMAGENETTE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3-B1TZyNu2xz"
      },
      "outputs": [],
      "source": [
        "classes = (\"Tench\", \"English Springer\", \"Cassette Player\", \"Chain Saw\", \"Church\", \"French Horn\", \"Garbage Truck\", \"Gas Pump\", \"Golf Ball\", \"Parachute\")\n",
        "batch_size = 32\n",
        "width = 224\n",
        "mean = [0.4655, 0.4546, 0.4251]\n",
        "std = [0.2775, 0.2725, 0.2938]\n",
        "\n",
        "def load_data():\n",
        "  train = source/\"train\"\n",
        "  val = source/\"val\"\n",
        "\n",
        "  train_dataset = ImageFolder(\n",
        "    train,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(width),\n",
        "        transforms.RandomCrop(width), \n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "        transforms.RandomErasing()\n",
        "    ]))\n",
        "\n",
        "  val_dataset = ImageFolder(\n",
        "    val,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(width),\n",
        "        transforms.RandomCrop(width), \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]))\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "  val_dataloader = DataLoader(val_dataset, batch_size)\n",
        "  \n",
        "  return train_dataloader, val_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx4i-oD0OKWP",
        "outputId": "8a8c8128-117b-4198-e5f5-0caa2fa0d4d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Y9DMp-u2x0"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Cxy6zB8Cu2x1"
      },
      "outputs": [],
      "source": [
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride=1, expansion=3, downsample=None):\n",
        "    super(block, self).__init__()\n",
        "    middle_channels = in_channels*expansion\n",
        "\n",
        "    self.pass1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, middle_channels, 1, stride=1, padding=0, bias=False),\n",
        "        nn.BatchNorm2d(middle_channels),\n",
        "        nn.Mish(),\n",
        "        nn.Conv2d(middle_channels, middle_channels, 3, stride=stride, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(middle_channels),\n",
        "        nn.Mish(),\n",
        "        nn.Conv2d(middle_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.Mish(),\n",
        "    )\n",
        "\n",
        "    self.pass2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, middle_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "        nn.BatchNorm2d(middle_channels),\n",
        "        nn.Mish(),\n",
        "        nn.Conv2d(middle_channels, middle_channels, kernel_size=3, stride=stride, padding=1,groups=in_channels, bias=False),\n",
        "        nn.BatchNorm2d(middle_channels),\n",
        "        nn.Mish(),\n",
        "        nn.Conv2d(middle_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.Mish(),\n",
        "    )\n",
        "\n",
        "    self.downsample = downsample\n",
        "  \n",
        "  def forward(self, x):\n",
        "    identity = x.clone()\n",
        "    x1 = self.pass1(x)\n",
        "    x2 = self.pass2(x)\n",
        "    x = x1 + x2\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(identity)\n",
        "    x += identity\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self, in_channels=3, num_classes=10):\n",
        "    super(Network, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "    self.mish = nn.Mish()\n",
        "\n",
        "    self.block1 = self._make_layer(block, 1, 32, 16, 1, 1)\n",
        "    self.block2 = self._make_layer(block, 6, 16, 24, 2, 2)\n",
        "    self.block3 = self._make_layer(block, 6, 24, 32, 3, 2)\n",
        "    self.block4 = self._make_layer(block, 6, 32, 64, 4, 2)\n",
        "    self.block5 = self._make_layer(block, 6, 64, 96, 3, 1)\n",
        "    self.block6 = self._make_layer(block, 6, 96, 160, 3, 2)\n",
        "    self.block7 = self._make_layer(block, 6, 160, 320, 1, 1)\n",
        "    \n",
        "    self.conv2 = nn.Conv2d(320,1280, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(1280)\n",
        "    self.avgPool = nn.AvgPool2d(7)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Linear(1280, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.mish(x)\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    x = self.block5(x)\n",
        "    x = self.block6(x)\n",
        "    x = self.block7(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.mish(x)\n",
        "    x = self.avgPool(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  def _make_layer(self, block, expansion, in_channels, out_channels, repeats, stride):\n",
        "    layers = []\n",
        "    downsample = None\n",
        "\n",
        "    if stride != 1 or in_channels != out_channels:\n",
        "      downsample = nn.Sequential(\n",
        "          nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(out_channels),\n",
        "      )\n",
        "\n",
        "\n",
        "    layers.append(\n",
        "        block(in_channels, out_channels, stride, expansion, downsample)\n",
        "    )\n",
        "\n",
        "    for _ in range(repeats-1):\n",
        "      layers.append(\n",
        "          block(out_channels, out_channels, 1, expansion)\n",
        "      )\n",
        "    \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "model = Network()\n",
        "\n",
        "# Injects a pretrained model\n",
        "\n",
        "# path = '/content/drive/MyDrive/Colab Notebooks/mix2v2/mix2 fully_residual CA bs32 81-115 99-89.pth'\n",
        "# model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSNynAhFu2x2"
      },
      "source": [
        "## Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lI8I5GzNu2x3"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam, SGD, lr_scheduler\n",
        "\n",
        "# Function to save the model\n",
        "def saveModel():\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/mix2 curr.pth'\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# Function to test the model with the test dataset and print the accuracy for the test images\n",
        "def testAccuracy(device):\n",
        "    \n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = model(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "def trainAccuracy(device):\n",
        "\n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in train_loader:\n",
        "            images, labels = data\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "            # run the model on the test set to predict labels\n",
        "            outputs = model(images)\n",
        "            # the label with the highest energy will be our prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "    \n",
        "    # compute the accuracy over all test images\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return(accuracy)\n",
        "\n",
        "def train(num_epochs):\n",
        "    \n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Define your execution device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"The model will be running on\", device, \"device\")\n",
        "    # Convert model parameters and buffers to CPU or Cuda\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    # Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=0.00024, weight_decay = 0.00001)\n",
        "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
        "    all_accuracy = []\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            # get the inputs\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # predict classes using images from the training set\n",
        "            outputs = model(images)\n",
        "            # compute the loss based on model output and real labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            # adjust parameters based on the calculated gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Let's print statistics for every 50 images\n",
        "            running_loss += loss.item()     # extract the loss value\n",
        "            if i % 10 == 10: # 10 means off\n",
        "                # print every 50 (twice per epoch) \n",
        "                print('[%d, %5d] loss: %.8f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                # zero the loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Compute and print the average accuracy for this epoch when tested over all test images\n",
        "        model.eval()\n",
        "        accuracy = testAccuracy(device)\n",
        "        train_accuracy = trainAccuracy(device)\n",
        "        all_accuracy.append(accuracy)\n",
        "        print('For epoch', epoch+1,'the train accuracy is %d %%' % (train_accuracy), 'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
        "        \n",
        "        # we want to save the model if the accuracy is the best\n",
        "        if accuracy > best_accuracy:\n",
        "            saveModel()\n",
        "            best_accuracy = accuracy\n",
        "\n",
        "        scheduler.step()\n",
        "    print('The average accuracy over %d' % num_epochs, ' runs is %.2f' % (sum(all_accuracy)/num_epochs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZXKn5Vau2x4"
      },
      "source": [
        "## Showing Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jhu6-ZnBu2x5"
      },
      "outputs": [],
      "source": [
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    if torch.cuda.is_available():\n",
        "      npimg = img.cpu().numpy()\n",
        "    else:\n",
        "      npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OpCcP0yCu2x5"
      },
      "outputs": [],
      "source": [
        "def checkTransformedImages():\n",
        "    # get batch of images from the test DataLoader\n",
        "    images, labels = next(iter(test_loader))\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Class Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnfuilM5PJzN",
        "outputId": "8c3b8f78-4d6d-430b-fe02-485e0b6e7d75"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "def class_accuracy():\n",
        "  train_loader, test_loader = load_data()\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  # prepare to count predictions for each class\n",
        "  correct_pred = {classname: 0 for classname in classes}\n",
        "  total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "  # again no gradients needed\n",
        "  with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = Variable(images.to(device))\n",
        "          labels = Variable(labels.to(device))\n",
        "          outputs = model(images)\n",
        "          _, predictions = torch.max(outputs, 1)\n",
        "          # collect the correct predictions for each class\n",
        "          for label, prediction in zip(labels, predictions):\n",
        "              if label == prediction:\n",
        "                  correct_pred[classes[label]] += 1\n",
        "              total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "  # print accuracy for each class\n",
        "  for classname, correct_count in correct_pred.items():\n",
        "      accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "      print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opk11Quiu2x6"
      },
      "source": [
        "Run Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzGEHXM6u2x6",
        "outputId": "4d470412-fae6-49c4-d057-a0d30c5c76b0"
      },
      "outputs": [],
      "source": [
        "train_loader, test_loader = load_data()\n",
        "\n",
        "num_epochs = 80\n",
        "train(num_epochs)\n",
        "\n",
        "checkTransformedImages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_accuracy()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "main_loop.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
